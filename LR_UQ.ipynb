{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQn/YH/v+eobjPOWSDjIZT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supsi-dacd-isaac/TeachDecisionMakingUncertainty/blob/main/LR_UQ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What do we do:\n",
        "We build a simple linear model to predict electricity consumption from 3 weather variables:\n",
        "$$\n",
        "y = \\beta X+\\epsilon  \n",
        "$$\n",
        "\n",
        "- $\\boxed{\\epsilon}$ is the **noise / irreducible randomness** usually $\\sim \\mathcal{N}(0,Ïƒ^2I)$.\n",
        "-  $\\boxed{\\beta_0, \\beta_1, \\beta_2, \\beta_3}$ are **model parameters**\n",
        "\n",
        "## 1) Load and prepare data\n",
        "- Download the dataset with `kagglehub.dataset_download(...)`\n",
        "- Load the CSV & Choose one target column `y` and predictor columns `X`\n",
        "\n",
        "## 2) Fit the regression model (OLS)\n",
        "\n",
        "**Ordinary Least Squares - OLS reminder**\n",
        "\n",
        "We choose the parameters $\\beta$ that minimize the sum of squared errors:\n",
        "$$\n",
        "\\hat{\\beta}=\\arg\\min_{\\beta}\\ \\sum_{i=1}^{n}\\left(y_i-\\mathbf{x}_i^\\top\\beta\\right)^2\n",
        "$$\n",
        "where $\\mathbf{x}_i=[1,\\ x_{i1},\\ x_{i2},\\ x_{i3}]^\\top$ includes the intercept.\n",
        "\n",
        "A nice and convinient way to the estimate coefficients with OLS is:\n",
        "$$\n",
        "\\hat\\beta = (X^\\top X)^{-1}X^\\top y\n",
        "$$\n",
        "We evaluate with root mean square error (RMSE) on train and test.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## 3) Uncertainty characterization\n",
        "### 3.a Aleatory (Gaussian residual model)\n",
        "### 3.b Aleatory (non-parametric residual model)\n",
        "---\n",
        "\n",
        "### 3.c Epistemic uncertainty (analytic covariance)  \n",
        "### 3.d Epistemic uncertainty (bootstrap)\n"
      ],
      "metadata": {
        "id": "kHNRnWrb2UVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load packages\n",
        "import os # operating system package\n",
        "import glob # Unix style pathname pattern expansion\n",
        "import kagglehub # useufl to import the data from Kaggle\n",
        "import numpy as np # process data and numerical computing\n",
        "import pandas as pd # tabular data package\n",
        "import matplotlib.pyplot as plt # plot and visualize\n",
        "import seaborn as sns  # plot and visualize from tables\n",
        "import plotly.graph_objects as go  # interactive plots"
      ],
      "metadata": {
        "id": "jEPE1rCNb6Cb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Load and prepare data\n",
        "\n",
        "\n",
        "**Description:**\n",
        "\n",
        "We will load a file that contains the daily electricity consumption and weather features. Each row represents one day with the following:\n",
        "\n",
        "- **date** - Date of observation\n",
        "- **AWND** - Average daily wind speed (m/s)\n",
        "- **PRCP** - Daily precipitation (mm)\n",
        "- **TMAX** - Daily maximum temperature (Â°C)\n",
        "- **TMIN** - Daily minimum temperature (Â°C)\n",
        "- **daily_consumption** - Total daily electricity consumption"
      ],
      "metadata": {
        "id": "cSeX3ofscgns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 1a) Colab setup: prepare Kaggle path where the dataset is\n",
        "# =========================================================\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"sudhirsingh27/electricity-consumption-based-on-weather-data\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# List files in the path\n",
        "files = sorted(glob.glob(os.path.join(path, \"**\", \"*\"), recursive=True))\n",
        "print(\"Files found in the path:\")\n",
        "for f in files:\n",
        "    if os.path.isfile(f):\n",
        "        print(\" -\", f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fjdr2GuuAFm",
        "outputId": "99693cc7-beb7-4963-eed6-776781bea7d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'electricity-consumption-based-on-weather-data' dataset.\n",
            "Path to dataset files: /kaggle/input/electricity-consumption-based-on-weather-data\n",
            "Files found in the path:\n",
            " - /kaggle/input/electricity-consumption-based-on-weather-data/electricity_consumption_based_weather_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 1b) Load and process the data\n",
        "# =========================================================\n",
        "\n",
        "# Load first CSV found\n",
        "csvs_files = sorted(glob.glob(os.path.join(path, \"**\", \"*.csv\"), recursive=True))\n",
        "if len(csvs_files) == 0:\n",
        "    raise FileNotFoundError(\"No CSV found in kagglehub dataset folder.\")\n",
        "csv_path = csvs_files[0]\n",
        "print(\"Loading this CSV file:\", csv_path)\n",
        "df = pd.read_csv(csv_path)\n",
        "print(\"Raw shape:\", df.shape)\n",
        "display(df.head(10))\n",
        "print(\"\\nColumns:\", list(df.columns))\n",
        "\n",
        "\n",
        "# --- Keep numeric columns  ---\n",
        "df_num = df.select_dtypes(include=[np.number]).copy()\n",
        "df_num['daily_consumption_previous'] = df_num['daily_consumption'].shift(1)\n",
        "df_num = df_num.dropna().reset_index(drop=True)\n",
        "print(\"Numeric-only shape:\", df_num.shape)\n",
        "display(df_num.head(10))\n",
        "\n",
        "\n",
        "# --- prepare data for simple tutorial  ---\n",
        "# Prefer y columns with these keywords; otherwise fallback to last numeric column\n",
        "\n",
        "x_cols = ['daily_consumption_previous_day', 'PRCP', 'TMAX']  # the explainatory variables\n",
        "y_col = 'daily_consumption'  # the target variables\n",
        "\n",
        "# transform pandas tabular data into arrays\n",
        "X_raw = df_num[x_cols].to_numpy()\n",
        "y = df_num[y_col].to_numpy()\n",
        "\n",
        "# Safely drop rows if NaNs or infs\n",
        "mask = np.isfinite(y) & np.all(np.isfinite(X_raw), axis=1)\n",
        "X_raw = X_raw[mask]\n",
        "y = y[mask]\n",
        "\n",
        "print(\"Final shapes -> X_raw:\", X_raw.shape, \"y:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c5EbPo8nuAH5",
        "outputId": "f3ece2ab-3bc3-4653-af85-3d1a3b606160"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading this CSV file: /kaggle/input/electricity-consumption-based-on-weather-data/electricity_consumption_based_weather_dataset.csv\n",
            "Raw shape: (1433, 6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         date  AWND  PRCP  TMAX  TMIN  daily_consumption\n",
              "0  2006-12-16   2.5   0.0  10.6   5.0           1209.176\n",
              "1  2006-12-17   2.6   0.0  13.3   5.6           3390.460\n",
              "2  2006-12-18   2.4   0.0  15.0   6.7           2203.826\n",
              "3  2006-12-19   2.4   0.0   7.2   2.2           1666.194\n",
              "4  2006-12-20   2.4   0.0   7.2   1.1           2225.748\n",
              "5  2006-12-21   2.3   0.0  12.2   3.3           1716.624\n",
              "6  2006-12-22   2.3  11.9   9.4   3.9           2341.338\n",
              "7  2006-12-23   3.0  19.8  15.0   8.9           4773.386\n",
              "8  2006-12-24   3.4   0.0  11.1   6.1           2550.012\n",
              "9  2006-12-25   2.2   9.4   7.2   3.9           2743.120"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b3fb2d2c-4a7f-41e0-88d8-8c823c07b414\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>AWND</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>daily_consumption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2006-12-16</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.6</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1209.176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2006-12-17</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.3</td>\n",
              "      <td>5.6</td>\n",
              "      <td>3390.460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006-12-18</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2203.826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2006-12-19</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.2</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1666.194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2006-12-20</td>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.2</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2225.748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2006-12-21</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1716.624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2006-12-22</td>\n",
              "      <td>2.3</td>\n",
              "      <td>11.9</td>\n",
              "      <td>9.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2341.338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2006-12-23</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.8</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>4773.386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2006-12-24</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2550.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2006-12-25</td>\n",
              "      <td>2.2</td>\n",
              "      <td>9.4</td>\n",
              "      <td>7.2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2743.120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b3fb2d2c-4a7f-41e0-88d8-8c823c07b414')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b3fb2d2c-4a7f-41e0-88d8-8c823c07b414 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b3fb2d2c-4a7f-41e0-88d8-8c823c07b414');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Final shapes -> X_raw:\\\", X_raw\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"2006-12-24\",\n          \"2006-12-17\",\n          \"2006-12-21\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AWND\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3719318934070233,\n        \"min\": 2.2,\n        \"max\": 3.4,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2.5,\n          2.6,\n          3.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRCP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.095295781165309,\n        \"min\": 0.0,\n        \"max\": 19.8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          11.9,\n          9.4,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TMAX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.0633315197673268,\n        \"min\": 7.2,\n        \"max\": 15.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          10.6,\n          13.3,\n          9.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TMIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.283783410629534,\n        \"min\": 1.1,\n        \"max\": 8.9,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8.9,\n          5.6,\n          3.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_consumption\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1010.1051157515133,\n        \"min\": 1209.176,\n        \"max\": 4773.386,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2550.012,\n          3390.46,\n          1716.624\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Columns: ['date', 'AWND', 'PRCP', 'TMAX', 'TMIN', 'daily_consumption']\n",
            "Numeric-only shape: (1417, 6)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   AWND  PRCP  TMAX  TMIN  daily_consumption  daily_consumption_previous\n",
              "0   2.6   0.0  13.3   5.6           3390.460                    1209.176\n",
              "1   2.4   0.0  15.0   6.7           2203.826                    3390.460\n",
              "2   2.4   0.0   7.2   2.2           1666.194                    2203.826\n",
              "3   2.4   0.0   7.2   1.1           2225.748                    1666.194\n",
              "4   2.3   0.0  12.2   3.3           1716.624                    2225.748\n",
              "5   2.3  11.9   9.4   3.9           2341.338                    1716.624\n",
              "6   3.0  19.8  15.0   8.9           4773.386                    2341.338\n",
              "7   3.4   0.0  11.1   6.1           2550.012                    4773.386\n",
              "8   2.2   9.4   7.2   3.9           2743.120                    2550.012\n",
              "9   3.3   2.0  11.7   6.1           3934.110                    2743.120"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cab12315-a0f7-4115-8a52-cb7e302f5708\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AWND</th>\n",
              "      <th>PRCP</th>\n",
              "      <th>TMAX</th>\n",
              "      <th>TMIN</th>\n",
              "      <th>daily_consumption</th>\n",
              "      <th>daily_consumption_previous</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>13.3</td>\n",
              "      <td>5.6</td>\n",
              "      <td>3390.460</td>\n",
              "      <td>1209.176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>6.7</td>\n",
              "      <td>2203.826</td>\n",
              "      <td>3390.460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.2</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1666.194</td>\n",
              "      <td>2203.826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.2</td>\n",
              "      <td>1.1</td>\n",
              "      <td>2225.748</td>\n",
              "      <td>1666.194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.2</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1716.624</td>\n",
              "      <td>2225.748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.3</td>\n",
              "      <td>11.9</td>\n",
              "      <td>9.4</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2341.338</td>\n",
              "      <td>1716.624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3.0</td>\n",
              "      <td>19.8</td>\n",
              "      <td>15.0</td>\n",
              "      <td>8.9</td>\n",
              "      <td>4773.386</td>\n",
              "      <td>2341.338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.1</td>\n",
              "      <td>6.1</td>\n",
              "      <td>2550.012</td>\n",
              "      <td>4773.386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2.2</td>\n",
              "      <td>9.4</td>\n",
              "      <td>7.2</td>\n",
              "      <td>3.9</td>\n",
              "      <td>2743.120</td>\n",
              "      <td>2550.012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3.3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.7</td>\n",
              "      <td>6.1</td>\n",
              "      <td>3934.110</td>\n",
              "      <td>2743.120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cab12315-a0f7-4115-8a52-cb7e302f5708')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cab12315-a0f7-4115-8a52-cb7e302f5708 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cab12315-a0f7-4115-8a52-cb7e302f5708');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"Final shapes -> X_raw:\\\", X_raw\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"AWND\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4398231968012197,\n        \"min\": 2.2,\n        \"max\": 3.4,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          2.6,\n          2.4,\n          2.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PRCP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.994037142849297,\n        \"min\": 0.0,\n        \"max\": 19.8,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          11.9,\n          2.0,\n          19.8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TMAX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.074284017819795,\n        \"min\": 7.2,\n        \"max\": 15.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          13.3,\n          15.0,\n          11.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TMIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3275165591963756,\n        \"min\": 1.1,\n        \"max\": 8.9,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          6.7,\n          3.9,\n          5.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_consumption\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 996.0416272516817,\n        \"min\": 1666.194,\n        \"max\": 4773.386,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2743.12,\n          2203.826,\n          2341.338\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"daily_consumption_previous\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1010.1051157515133,\n        \"min\": 1209.176,\n        \"max\": 4773.386,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2550.012,\n          3390.46,\n          1716.624\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['daily_consumption_previous_day'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-29826807.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# transform pandas tabular data into arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mX_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['daily_consumption_previous_day'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we prepare $\\mathbf{x}_i=[1,\\ x_{i1},\\ x_{i2},\\ x_{i3}]^\\top$ to include the intercept\n"
      ],
      "metadata": {
        "id": "zcAz76W2egAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build design matrix (add intercept column)\n",
        "n = len(y)\n",
        "X = np.c_[np.ones((n, 1)), X_raw]  # (n, 4) = [1, x1, x2, x3]\n",
        "\n",
        "# Train/test split\n",
        "rng = np.random.default_rng(0)\n",
        "perm = rng.permutation(n)\n",
        "n_train = int(0.8 * n)\n",
        "idx_train, idx_test = perm[:n_train], perm[n_train:]\n",
        "X_train, y_train = X[idx_train], y[idx_train]\n",
        "X_test, y_test = X[idx_test], y[idx_test]\n",
        "X_raw_train = X_raw[idx_train]\n",
        "X_raw_test = X_raw[idx_test]\n",
        "print(\"Train shapes:\", X_train.shape, y_train.shape)\n",
        "print(\"Test shapes :\", X_test.shape, y_test.shape)\n",
        "\n",
        "# Quick look at the data using pairplot matrix using seaborn\n",
        "sample_n = min(1000, len(y))\n",
        "sidx = rng.choice(len(y), size=sample_n, replace=False)\n",
        "df_plot = pd.DataFrame(X_raw[sidx], columns=x_cols)\n",
        "df_plot[y_col] = y[sidx]\n",
        "sns.pairplot(df_plot, corner=True, diag_kind=\"hist\")\n",
        "plt.suptitle(\"Pairplot (sampled)\", y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b8TX9SebzGLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Fit the regression model (OLS)\n",
        "We know that the coefficients for OLS can be found solving this:\n",
        "\n",
        "$$\n",
        "\\hat\\beta = (X^\\top X)^{-1}X^\\top y\n",
        "$$\n",
        "\n",
        "This means we will solve a linear system in the form\n",
        "$$\n",
        "(X^\\top X) \\hat\\beta = X^\\top y\n",
        "$$\n",
        "\n",
        "Or simply:\n",
        "\n",
        "$$\n",
        "A \\hat\\beta = b\n",
        "$$\n",
        ""
      ],
      "metadata": {
        "id": "yVUwghUdep9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2a) Fit linear regression - use ordinary least square OLS\n",
        "# =========================================================\n",
        "\n",
        "# fit lineart model\n",
        "A = X_train.T @ X_train\n",
        "b = X_train.T @ y_train\n",
        "beta_hat = np.linalg.solve(A, b) # numpy solver for linear programs\n",
        "\n",
        "# predict and RMSE\n",
        "yhat_train = X_train @ beta_hat # get predictions on the training set\n",
        "yhat_test = X_test @ beta_hat # get predictions on the test set\n",
        "\n",
        "rmse_train = float(np.sqrt(np.mean((y_train - yhat_train) ** 2))) # RMSE training\n",
        "rmse_test = float(np.sqrt(np.mean((y_test - yhat_test) ** 2))) # RMSE test\n",
        "\n",
        "# print\n",
        "print(\"beta_hat:\", beta_hat)\n",
        "print(\"RMSE train:\", rmse_train)\n",
        "print(\"RMSE test :\", rmse_test)"
      ],
      "metadata": {
        "id": "2Cn9xDpIzRjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2b) Add the fitted plane (y = bX) to the scatter plot data\n",
        "#     using plotly.graph_objects as go (movable image)\n",
        "#\n",
        "# NOTE: With 3 predictors,\n",
        "#               - We will show a 3D surface using two variables\n",
        "#               - We will keep the 3rd fixed at its mean value\n",
        "# =========================================================\n",
        "\n",
        "b0, b1, b2, b3  = beta_hat\n",
        "x1_name, x2_name, x3_name = x_cols[0], x_cols[1], x_cols[2]\n",
        "x1, x2, x3 = X_raw[:,0], X_raw[:,1], X_raw[:,2]\n",
        "x2_fixed = float(np.mean(x2))\n",
        "\n",
        "# Grid for surface\n",
        "x1g = np.linspace(x1.min(), x1.max(), 60)\n",
        "x3g = np.linspace(x3.min(), x3.max(), 60)\n",
        "X1g, X3g = np.meshgrid(x1g, x3g)\n",
        "Yg = b0 + b1 * X1g + b2 * x2_fixed + b3 * X3g\n",
        "\n",
        "# Subsample points for speed\n",
        "sub = rng.choice(len(y), size=min(2500, len(y)), replace=False)\n",
        "\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Scatter3d(\n",
        "    x=x1[sub], y=x3[sub], z=y[sub],\n",
        "    mode=\"markers\",\n",
        "    marker=dict(size=3, opacity=0.6),\n",
        "    name=\"data\"\n",
        "))\n",
        "fig.add_trace(go.Surface(\n",
        "    x=X1g, y=X3g, z=Yg,\n",
        "    opacity=0.5,\n",
        "    showscale=False,\n",
        "    name=f\"OLS surface (x2 fixed at mean={x2_fixed:.3f})\"\n",
        "))\n",
        "fig.update_layout(\n",
        "    scene=dict(xaxis_title=x1_name, yaxis_title=x3_name, zaxis_title=y_col),\n",
        "    width=900, height=650\n",
        ")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "lz5k3auzzKii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3) Uncertainty characterization\n",
        "### 3.a Aleatory (Parametric Gaussian residual model)\n",
        "\n",
        "We now try to model $\\epsilon$, the error distribution modelling variability in the data.\n",
        "\n",
        "More data can improve the model, but data cannot remove the variability, hence it is  **characterized as ALEATORIC**\n",
        "\n",
        "\n",
        "\n",
        "Residuals:\n",
        "$$\n",
        "r_i = y_i - \\hat y_i\n",
        "$$\n",
        "\n",
        "Unbiased noise estimate:\n",
        "$$\n",
        "\\hat\\sigma^2 = \\frac{1}{n-p}\\sum r_i^2\n",
        "$$\n",
        "\n",
        "We visualize the residual histogram and a fitted $\\epsilon\\sim \\mathcal{N}(0,\\sigma^2)$.\n",
        "\n",
        "\n",
        "**REMARK:**\n",
        "\n",
        "Why dont we use `np.std(residual)`\n",
        "\n",
        "ðŸ‘‰ Because we must correct for the number of estimated parameters.\n",
        "\n",
        "Note that `np.std(resid, ddof=p)` is equivalent\n",
        "\n",
        "\n",
        "### 3.b Aleatory (non-parametric residual model)\n",
        "We resample the residuals directly instead of assuming a Gaussian shape:\n",
        "$$\n",
        "r_i = y^{new}_i - \\hat y_i\n",
        "$$\n",
        "This gives a non-parametric predictive distribution of the errors."
      ],
      "metadata": {
        "id": "VImS-G7fhRd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3. START UNCERTAINTY CHARACTERIZATION\n",
        "# 3.a) Aleatory uncertainty --> residuals assuming gaussian distribution\n",
        "# =========================================================\n",
        "\n",
        "resid = y_train - yhat_train\n",
        "p = X_train.shape[1]  # parameters incl intercept\n",
        "sigma2_hat = float((resid @ resid) / (len(y_train) - p))\n",
        "sigma_hat = float(np.sqrt(sigma2_hat))\n",
        "print(\"sigma_hat (Gaussian residual model):\", sigma_hat)\n",
        "\n",
        "# show bias Var(epsilon) estimator if p not accounted for\n",
        "print('Show bias:')\n",
        "print('standard deviation for p=1,', np.std(resid))\n",
        "print(f'standard deviation for p={p},',np.std(resid, ddof=p))\n",
        "\n",
        "\n",
        "# Residual diagnostics\n",
        "plt.figure()\n",
        "plt.scatter(yhat_train, resid, s=10, alpha=0.6)\n",
        "plt.axhline(0)\n",
        "plt.title(\"Residuals vs fitted (train)\")\n",
        "plt.xlabel(\"fitted y\")\n",
        "plt.ylabel(\"residual\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Show predictive distributions\n",
        "plt.figure()\n",
        "counts, edges, _ = plt.hist(resid, bins=30, density=True, alpha=0.6)\n",
        "xx = np.linspace(resid.min(), resid.max(), 400)\n",
        "pdf = (1.0 / (np.sqrt(2*np.pi) * sigma_hat)) * np.exp(-0.5 * (xx / sigma_hat)**2) # equation for the gaussain PDF\n",
        "plt.plot(xx, pdf, linewidth=2, label=r\"Normal(0, $\\hat\\sigma^2$)\")\n",
        "plt.title(\"Residual histogram + fitted Gaussian\")\n",
        "plt.xlabel(\"residual\")\n",
        "plt.ylabel(\"density\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "6jUlekO312lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "## A bit of DIAGNOSTIC:\n",
        "\n",
        "# ARE THE RESIDUALS NORMAL DISTRIBUTED?\n",
        "\n",
        "\n",
        "from scipy import stats\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# MUST BE BOTH 0 for Gaussian\n",
        "print(\"Skewness:\", stats.skew(resid))\n",
        "print(\"Excess Kurtosis:\", stats.kurtosis(resid))\n",
        "\n",
        "# Shapiroâ€“Wilk tests:\n",
        "# H0â€‹:Residuals are normally distributed\n",
        "stat, p_value = stats.shapiro(resid)\n",
        "print(\"Shapiro-Wilk statistic:\", stat)\n",
        "print(\"Shapiro-Wilk p-value:\", p_value)\n",
        "\n",
        "# QQ plot\n",
        "# H0â€‹:Residuals are normally distributed\n",
        "\n",
        "resid_sorted = np.sort(resid)# Sort residuals\n",
        "n = len(resid_sorted)# Sample size\n",
        "\n",
        "# Theoretical quantiles from standard normal\n",
        "theoretical_q = stats.norm.ppf((np.arange(1, n + 1) - 0.5) / n)\n",
        "\n",
        "# Standardize residuals (empirical spread of residual vector ddof=1)\n",
        "resid_std = (resid_sorted - np.mean(resid_sorted)) / np.std(resid_sorted, ddof=1)\n",
        "\n",
        "# Plot\n",
        "plt.figure()\n",
        "plt.scatter(theoretical_q, resid_std, s=15, alpha=0.7)\n",
        "\n",
        "# add 45-degree reference line (target )\n",
        "min_q = min(theoretical_q.min(), resid_std.min())\n",
        "max_q = max(theoretical_q.max(), resid_std.max())\n",
        "plt.plot([min_q, max_q], [min_q, max_q], color='red', linewidth=2)\n",
        "\n",
        "plt.title(\"Q-Q Plot \")\n",
        "plt.xlabel(\"Theoretical Quantiles (Normal)\")\n",
        "plt.ylabel(\"Standardized Residual Quantiles\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fWsHgrmerKdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.c) Epistemic uncertainty (Confidence Intervals on parameters)\n",
        "\n",
        "Because we only have a finite dataset, the OLS estimate $\\hat\\beta$ is not a fixed number. It is a **uncertain quantitiy** that would change if we collected a different dataset (new measurements, different days).\n",
        "\n",
        "More data can reduce this uncertainty, hence,it is **characterized as EPISTEMIC**\n",
        "\n",
        "----\n",
        "###  --> Confidence Intervals via analytic covariance\n",
        "Under the i.i.d. Gaussian noise assumption, $\\hat\\beta$ is (approximately) Gaussian and its estimated covariance is:\n",
        "$$\n",
        "\\widehat{\\mathrm{Var}}(\\hat\\beta)= \\hat\\sigma^2  (X^\\top X)^{-1}.\n",
        "$$\n",
        "with the estimated variance obtained from the training residuals:\n",
        "$$\n",
        "\\hat\\sigma^2 = \\frac{1}{n-p}\\sum_{i=1}^n (y_i-\\hat y_i)^2,\n",
        "$$\n",
        "where $p$ is the number of parameters.\n",
        "\n",
        "From this covariance matrix we can get:\n",
        "- The **standard error** of coefficient $j$ is\n",
        " $$\n",
        "  \\mathrm{SE}(\\hat\\beta_j)=\\sqrt{\\left[\\widehat{\\mathrm{Var}}(\\hat\\beta)\\right]_{jj}}.\n",
        "$$\n",
        "This is simply the square root of the j-th diagonal element\n",
        "\n",
        "\n",
        "- A (approx.) **95% confidence interval** is\n",
        "$$\n",
        "  \\hat\\beta_j \\pm z_{0.975}\\,\\mathrm{SE}(\\hat\\beta_j),\n",
        "$$\n",
        "  with $z_{0.975}\\approx 1.96$.  \n",
        "\n",
        "**Interpretation:** if we repeated â€œcollect data + fit OLSâ€ many times, about 95% of these intervals would contain the true coefficient $\\beta_j$.\n",
        "\n",
        "\n",
        "----\n",
        "###  --> Confidence Intervals via bootstraping\n",
        "\n",
        "The analytic formula above relies on assumptions (especially i.i.d. Gaussian noise and a correct linear model). The **bootstrap** is a data-driven alternative that estimates parameter uncertainty by *simulating repeated datasets* from the one we have.\n",
        "\n",
        "**Pairs bootstrap (what we do):**\n",
        "1. Sample rows $(x_i, y_i)$ from the training set **with replacement** (same number of rows as the original training set).\n",
        "2. Fit OLS on this bootstrap dataset â†’ obtain $\\hat\\beta^{(b)}$.\n",
        "3. Repeat for $b=1,\\dots,B$.\n",
        "\n",
        "This produces many plausible coefficient values:\n",
        "$$\n",
        "\\hat\\beta^{(1)},\\hat\\beta^{(2)},\\dots,\\hat\\beta^{(B)}.\n",
        "$$\n",
        "Their spread represents **epistemic uncertainty**. A simple **bootstrap confidence interval** (percentile method) for coefficient $j$ is:\n",
        "$$\n",
        "\\left[\\,Q_{0.025}(\\hat\\beta_j^{(b)}),\\ Q_{0.975}(\\hat\\beta_j^{(b)})\\,\\right].\n",
        "$$\n",
        "\n",
        "**Why bootstrap is useful:** it is simple, intuitive â€œrefit many timesâ€, and can work well even when the distributional assumptions are not perfect.\n",
        "\n"
      ],
      "metadata": {
        "id": "llNmVx3Pmlwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## =========================================================\n",
        "# 3.c) Epistemic uncertainty --> analytic covariance of beta_hat\n",
        "# =========================================================\n",
        "\n",
        "XtX_inv = np.linalg.inv(A)\n",
        "cov_beta = sigma2_hat * XtX_inv\n",
        "se_beta = np.sqrt(np.diag(cov_beta))\n",
        "\n",
        "# get confidence interval via asymptotic approximation\n",
        "z = 1.96\n",
        "beta_ci_low = beta_hat - z * se_beta\n",
        "beta_ci_high = beta_hat + z * se_beta\n",
        "\n",
        "names = [\"intercept\"] + [f\"beta_{c}\" for c in x_cols]\n",
        "\n",
        "print(\"\\nAnalytic parameter uncertainty (approx 95% CI)\")\n",
        "for j, name in enumerate(names):\n",
        "    print(f\"{name:15s}: {beta_hat[j]: .6f}  (SE {se_beta[j]:.6f})  \"\n",
        "          f\"CI [{beta_ci_low[j]:.6f}, {beta_ci_high[j]:.6f}]\")\n"
      ],
      "metadata": {
        "id": "DLq6ZCCz12rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cov_beta"
      ],
      "metadata": {
        "id": "HHome7aSpCHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 3.d) Epistemic uncertainty --> bootstrap CI for the parameters beta_hat\n",
        "# =========================================================\n",
        "\n",
        "B = 1000  # number of times we will repeat the fitting\n",
        "beta_boot = np.zeros((B, X_train.shape[1]))\n",
        "ntr = len(y_train)\n",
        "\n",
        "for b in range(B): # repeat fitting many times\n",
        "    ib = rng.integers(0, ntr, size=ntr) # random integer for row selection\n",
        "    Xb = X_train[ib] # random subset of X\n",
        "    yb = y_train[ib] # random subset of y\n",
        "    beta_boot[b] = np.linalg.solve(Xb.T @ Xb, Xb.T @ yb)\n",
        "\n",
        "boot_low = np.quantile(beta_boot, 0.025, axis=0)\n",
        "boot_high = np.quantile(beta_boot, 0.975, axis=0)\n",
        "\n",
        "print(\"\\nBootstrap parameter uncertainty (95% percentile CI)\")\n",
        "for j, name in enumerate(names):\n",
        "    print(f\"{name:15s}: mean={beta_boot[:,j].mean(): .6f}  \"\n",
        "          f\"CI [{boot_low[j]:.6f}, {boot_high[j]:.6f}]\")\n",
        "\n",
        "# Optional: show bootstrap histograms\n",
        "for j, name in enumerate(names):\n",
        "    plt.figure(figsize=(10, 3))\n",
        "    plt.hist(beta_boot[:, j], bins=30)\n",
        "    plt.title(f\"Bootstrap distribution: {name}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "T39w-AxXbhiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# Visualize uncertainty\n",
        "# =========================================================\n",
        "\n",
        "j = 1   # index of variable (excluding intercept)\n",
        "xj = X_train[:, j]\n",
        "xj_grid = np.linspace(xj.min(), xj.max(), 200)\n",
        "\n",
        "# Start from mean design vector\n",
        "x_mean = X_train.mean(axis=0)\n",
        "\n",
        "# Build grid design matrix\n",
        "X_grid = np.tile(x_mean, (len(xj_grid), 1))\n",
        "X_grid[:, j] = xj_grid\n",
        "\n",
        "y_mean  = X_grid @ beta_hat\n",
        "y_low   = X_grid @ boot_low\n",
        "y_high  = X_grid @ boot_high\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_train[:, j], y_train, s=15, alpha=0.4)\n",
        "plt.plot(xj_grid, y_mean, linewidth=2, c='r', label=\"Mean fit\")\n",
        "plt.plot(xj_grid, y_low, linestyle=\"--\", c='k', label=\"Lower CI plane\")\n",
        "plt.plot(xj_grid, y_high, linestyle=\"--\", c='k', label=\"Upper CI plane\")\n",
        "\n",
        "plt.xlabel(f\"Predictor {j}\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Epistemic Uncertainty (Slice of Hyperplane)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Aleatory (residual) predictive band\n",
        "\n",
        "z = 1.96\n",
        "y_low_pred  = y_mean - z * sigma_hat\n",
        "y_high_pred = y_mean + z * sigma_hat\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(X_train[:, j], y_train, s=15, alpha=0.4, label=\"Data\")\n",
        "plt.plot(xj_grid, y_mean, linewidth=2, label=\"Mean fit\")\n",
        "\n",
        "# Aleatory predictive band (Gaussian noise)\n",
        "plt.fill_between(xj_grid,\n",
        "                 y_low_pred,\n",
        "                 y_high_pred,\n",
        "                 alpha=0.2,\n",
        "                 label=\"Aleatory predictive band (Â±1.96Ïƒ)\")\n",
        "\n",
        "plt.xlabel(f\"Predictor {j}\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"Epistemic + Aleatory Uncertainty\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3uWOJ7Ghpx8a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}